searchState.loadedDescShard("nn", 0, "Functions for training and evaluating neural nets.\nGeometry of a neural net.\nThe type of net weights, inputs, and outputs.\nA neural net that can be used to map inputs to outputs.\nInfrastructure for evaluating a net, without the weights.\nA neural net in training.\nThe weights of a neural network.\nForget the weights, just keep the runner state for later …\nExtract net and destroy training infrastructure.\nGet the dimension of this net.\nEvaluate the net on the current input.\nEvaluate the net on the current input.\nUpdate the net’s state based on the examples in the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the output of the net.\nGet the results of evaluating the net. Only valid after …\nThe current state of the net.\nHow many hidden layers we have.\nHow big is each hidden layer.\nNumber of inputs to the net.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nDetermines how much to change the net’s state based on a …\nLoad some weights from a file.\nCrate a new runner using the given weights.\nCreate a new net where all weights are a constant.\nCreate a trainer for the given net.\nSpecifies how to normalize and validate the result of a …\nNumber of results produced by the net.\nPrint the network to stdout.  This is mostly useful for …\nSet the weights to random numbers in the given range …\nSave the weights to a file.\nGet a reference to fill in the input to the net.\nGet a buffer to fill with the net’s input.\nGet a buffer to fill a desired output.\nTrain based on the current input output pair.  For batch …\nThe type of actions for this transition system.\nThe type of net weights, inputs, and outputs.\nSerialize to a sequence of numbers.\nStateful transition systems.\nThe state of an agent in training.\nHow much weight to give to new local rewards\nNotify agent that the run is finished.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nTransition to the next state, using the given action, and …\nPick one of the given actions and transitions to next …\nEncode the value in the given buffer and return how many …\nHow to normalize internal results of the net.\nNormalize internal values using <code>sigmoid</code>.\nHow to normalize the internal results computed by the net.\nHow to normalize values computed by the network.\nNormalize the outputs with <code>sigmoid</code>. Error is computed as …\nNormalize outputs with <code>softmax</code>, and use <code>cross-entropy</code> to …\nHow to normalize the output of the net.\nDon’t normalize the outputs. Error is computed as half …\nHow to compute and validate the output of the net.\nThe type of net weights, inputs, and outputs.\nCompute the error for the given results.\nCompute the error gradient.   The error gradient is …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nNormalize an internally computed value.\nThe gradient of the normalization function, in terms of …\nNormalize the given results.")